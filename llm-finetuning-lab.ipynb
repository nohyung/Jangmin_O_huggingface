{"cells":[{"cell_type":"markdown","id":"cb7e8082-2e4d-4d20-8fd0-ef802bb53894","metadata":{"id":"cb7e8082-2e4d-4d20-8fd0-ef802bb53894"},"source":["# gemma-2b-it 모델 미세 튜닝 실습"]},{"cell_type":"markdown","id":"830f173b-3ed7-4cb8-98e1-cd70a166fbe1","metadata":{"id":"830f173b-3ed7-4cb8-98e1-cd70a166fbe1"},"source":["개요\n","- 음식 주문 분석 데이터셋: 3000건\n","   - 문제: 주문 문장으로부터 음식명/옵션명/수량 추출\n","- gemma-2b-it 를 미세 튜닝하여 달성\n","- 방법\n","    - 4비트 양자화 로딩\n","    - LoRA 어댑터 장착\n","    - SFTTrainer 를 이용한 훈련: 문장 -> 다음 토큰 예측\n","    - 데이터셋을 ConstantLengthDataset으로 처리"]},{"cell_type":"code","source":["pip install wandb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VSwML8R3eepc","executionInfo":{"status":"ok","timestamp":1720578628399,"user_tz":-540,"elapsed":21262,"user":{"displayName":"Jangmin O","userId":"17786016660281478273"}},"outputId":"db438841-1ebd-4d9c-ee30-853c8f7aae4a"},"id":"VSwML8R3eepc","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting wandb\n","  Downloading wandb-0.17.4-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n","Collecting docker-pycreds>=0.4.0 (from wandb)\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n","  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.2.2)\n","Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n","Collecting sentry-sdk>=1.0.0 (from wandb)\n","  Downloading sentry_sdk-2.8.0-py2.py3-none-any.whl (300 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.6/300.6 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting setproctitle (from wandb)\n","  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n","Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n","  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.6.2)\n","Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n","  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n","Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, gitpython, wandb\n","Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 sentry-sdk-2.8.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.4\n"]}]},{"cell_type":"code","source":["!pip install transformers accelerate datasets peft trl bitsandbytes wandb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rX0daM3gdLFE","executionInfo":{"status":"ok","timestamp":1720578391017,"user_tz":-540,"elapsed":103765,"user":{"displayName":"Jangmin O","userId":"17786016660281478273"}},"outputId":"b64149f8-e5be-433e-a254-79341b43bec3"},"id":"rX0daM3gdLFE","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n","Collecting accelerate\n","  Downloading accelerate-0.32.1-py3-none-any.whl (314 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets\n","  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting peft\n","  Downloading peft-0.11.1-py3-none-any.whl (251 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting trl\n","  Downloading trl-0.9.6-py3-none-any.whl (245 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/245.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting bitsandbytes\n","  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n","Collecting pyarrow>=15.0.0 (from datasets)\n","  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n","Collecting requests (from transformers)\n","  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting xxhash (from datasets)\n","  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n","Collecting tyro>=0.5.11 (from trl)\n","  Downloading tyro-0.8.5-py3-none-any.whl (103 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.4/103.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n","  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (0.16)\n","Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.7.1)\n","Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n","  Downloading shtab-1.7.1-py3-none-any.whl (14 kB)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.16.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n","Installing collected packages: xxhash, shtab, requests, pyarrow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, tyro, nvidia-cusolver-cu12, datasets, bitsandbytes, accelerate, trl, peft\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.31.0\n","    Uninstalling requests-2.31.0:\n","      Successfully uninstalled requests-2.31.0\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 14.0.2\n","    Uninstalling pyarrow-14.0.2:\n","      Successfully uninstalled pyarrow-14.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n","google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n","ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed accelerate-0.32.1 bitsandbytes-0.43.1 datasets-2.20.0 dill-0.3.8 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 peft-0.11.1 pyarrow-16.1.0 requests-2.32.3 shtab-1.7.1 trl-0.9.6 tyro-0.8.5 xxhash-3.4.1\n"]}]},{"cell_type":"code","execution_count":2,"id":"98776311-5d88-46e0-ae19-ad118f10c107","metadata":{"id":"98776311-5d88-46e0-ae19-ad118f10c107","executionInfo":{"status":"ok","timestamp":1720578651631,"user_tz":-540,"elapsed":17973,"user":{"displayName":"Jangmin O","userId":"17786016660281478273"}}},"outputs":[],"source":["import os\n","from dataclasses import dataclass, field\n","from typing import Optional\n","import re\n","\n","import torch\n","import sys\n","import tyro\n","from accelerate import Accelerator\n","from datasets import load_dataset, Dataset\n","from peft import AutoPeftModelForCausalLM, LoraConfig\n","from tqdm import tqdm\n","from transformers import (\n","    HfArgumentParser,\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    BitsAndBytesConfig,\n","    TrainingArguments,\n","    TextStreamer,\n","    logging as hf_logging,\n",")\n","import logging\n","from trl import SFTTrainer, SFTConfig\n","\n","from trl.trainer import ConstantLengthDataset"]},{"cell_type":"markdown","id":"2267ff1b-5cc5-4374-87f3-a1e26ab1ea05","metadata":{"id":"2267ff1b-5cc5-4374-87f3-a1e26ab1ea05"},"source":["# 설정값"]},{"cell_type":"code","execution_count":3,"id":"424ade05-83c1-4dc2-b1a1-8a15b87345fb","metadata":{"id":"424ade05-83c1-4dc2-b1a1-8a15b87345fb","executionInfo":{"status":"ok","timestamp":1720578655123,"user_tz":-540,"elapsed":567,"user":{"displayName":"Jangmin O","userId":"17786016660281478273"}}},"outputs":[],"source":["base_model_id = \"google/gemma-2b-it\"\n","device_map=\"cuda\"\n","torch_dtype = torch.bfloat16\n","output_dir = \"./gemma-order-analysis\"\n","dataset_name = \"./llm-modeling-lab.jsonl\"\n","seq_length = 512"]},{"cell_type":"markdown","id":"ac8f5418-3ad1-4433-a55e-e70decfc4ae2","metadata":{"id":"ac8f5418-3ad1-4433-a55e-e70decfc4ae2"},"source":["# 원본 데이터셋"]},{"cell_type":"code","execution_count":4,"id":"c58ccc56-06f3-4dc4-bb72-070a734ec55f","metadata":{"id":"c58ccc56-06f3-4dc4-bb72-070a734ec55f","executionInfo":{"status":"ok","timestamp":1720578655698,"user_tz":-540,"elapsed":2,"user":{"displayName":"Jangmin O","userId":"17786016660281478273"}}},"outputs":[],"source":["full_dataset = Dataset.from_json(path_or_paths=dataset_name)"]},{"cell_type":"markdown","id":"995f9c64-9a6c-46ee-8e45-7bb01c8a06cc","metadata":{"id":"995f9c64-9a6c-46ee-8e45-7bb01c8a06cc"},"source":["# 토크나이저 로딩"]},{"cell_type":"code","execution_count":5,"id":"10d7fd4f-cd39-49a6-a03d-0b34678f45bf","metadata":{"id":"10d7fd4f-cd39-49a6-a03d-0b34678f45bf","executionInfo":{"status":"ok","timestamp":1720578658462,"user_tz":-540,"elapsed":2766,"user":{"displayName":"Jangmin O","userId":"17786016660281478273"}}},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\n","    base_model_id\n",")\n","tokenizer.padding_side = \"right\""]},{"cell_type":"markdown","id":"187b1c68-e1da-4301-8525-c335240f0aea","metadata":{"id":"187b1c68-e1da-4301-8525-c335240f0aea"},"source":["# 베이스 모델 로딩"]},{"cell_type":"code","execution_count":6,"id":"95e5f217-c11a-4ca4-b937-121ed7f79cc8","metadata":{"id":"95e5f217-c11a-4ca4-b937-121ed7f79cc8","executionInfo":{"status":"ok","timestamp":1720578658462,"user_tz":-540,"elapsed":3,"user":{"displayName":"Jangmin O","userId":"17786016660281478273"}}},"outputs":[],"source":["lora_config = LoraConfig(\n","            r=8,\n","            lora_alpha=16,\n","            lora_dropout=0.05,\n","            target_modules=[\n","                \"q_proj\",\n","                \"k_proj\",\n","                \"v_proj\",\n","                \"o_proj\",\n","                \"down_proj\",\n","                \"up_proj\",\n","                \"gate_proj\",\n","            ],\n","            bias=\"none\",\n","            task_type=\"CAUSAL_LM\",\n","        )"]},{"cell_type":"code","execution_count":7,"id":"103caa04-8a09-4605-a281-e6e780cfe704","metadata":{"id":"103caa04-8a09-4605-a281-e6e780cfe704","executionInfo":{"status":"ok","timestamp":1720578658462,"user_tz":-540,"elapsed":2,"user":{"displayName":"Jangmin O","userId":"17786016660281478273"}}},"outputs":[],"source":["\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.bfloat16,\n",")"]},{"cell_type":"code","execution_count":8,"id":"f32bf7fc-5b99-4170-95fc-abec8b50a0ed","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":118,"referenced_widgets":["f5bcd287d4fe401c9bec81288dc83cfd","aeb93fee4c8c400a9883ffc945c76838","669c3f8f432d4435a28136539f8c8328","b05ece34370f418886cbcf8af5cd6adc","1d871e675b8741f0b48f23300c9fc0ee","8f2a9534254341f9881df6e431f35e34","97ff3bb8e7a8499eb34b47104b9f8a17","f662959cb24145f7a33e82e92eab2025","84b08b2feef94d3eaa65dbdfb0f0e8b3","be76b22994dc48238836d805c9239642","c8887b8b829c475682ad5b21ebf7eb10"]},"id":"f32bf7fc-5b99-4170-95fc-abec8b50a0ed","executionInfo":{"status":"ok","timestamp":1720578679482,"user_tz":-540,"elapsed":21022,"user":{"displayName":"Jangmin O","userId":"17786016660281478273"}},"outputId":"d62a9fcd-7125-4330-d558-25823cd542ef"},"outputs":[{"output_type":"stream","name":"stderr","text":["`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n","Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n","`config.hidden_activation` if you want to override this behaviour.\n","See https://github.com/huggingface/transformers/pull/29402 for more details.\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5bcd287d4fe401c9bec81288dc83cfd"}},"metadata":{}}],"source":["base_model = AutoModelForCausalLM.from_pretrained(\n","    base_model_id,\n","    quantization_config=bnb_config,\n","    device_map=\"auto\",  # {\"\": Accelerator().local_process_index},\n",")"]},{"cell_type":"code","execution_count":9,"id":"e6412ea2-576f-4a95-b941-6c55ef4b1490","metadata":{"id":"e6412ea2-576f-4a95-b941-6c55ef4b1490","executionInfo":{"status":"ok","timestamp":1720578679482,"user_tz":-540,"elapsed":19,"user":{"displayName":"Jangmin O","userId":"17786016660281478273"}}},"outputs":[],"source":["base_model.config.use_cache = False"]},{"cell_type":"code","execution_count":10,"id":"70fa9eca-c965-4e7a-8f46-d145113731b2","metadata":{"id":"70fa9eca-c965-4e7a-8f46-d145113731b2","executionInfo":{"status":"ok","timestamp":1720578679482,"user_tz":-540,"elapsed":18,"user":{"displayName":"Jangmin O","userId":"17786016660281478273"}}},"outputs":[],"source":["peft_config = lora_config"]},{"cell_type":"code","execution_count":11,"id":"3d148097-9770-4743-ad28-40d7952e1ee0","metadata":{"id":"3d148097-9770-4743-ad28-40d7952e1ee0","executionInfo":{"status":"ok","timestamp":1720578679482,"user_tz":-540,"elapsed":18,"user":{"displayName":"Jangmin O","userId":"17786016660281478273"}}},"outputs":[],"source":["if getattr(tokenizer, \"pad_token\", None) is None:\n","    tokenizer.pad_token = tokenizer.eos_token\n","    tokenizer.pad_token_id = tokenizer.eos_token_id\n","tokenizer.padding_side = \"right\"  # Fix weird overflow issue with fp16 training\n","if base_model.config.pad_token_id != tokenizer.pad_token_id:\n","    base_model.config.pad_token_id = tokenizer.pad_token_id"]},{"cell_type":"markdown","id":"e2f4c432-9c07-4f82-9c6e-4b5625d3ffa4","metadata":{"id":"e2f4c432-9c07-4f82-9c6e-4b5625d3ffa4"},"source":["# 유틸리티"]},{"cell_type":"code","execution_count":12,"id":"20dc069b-19f6-4c22-8f6f-ef7fa380ca01","metadata":{"id":"20dc069b-19f6-4c22-8f6f-ef7fa380ca01","executionInfo":{"status":"ok","timestamp":1720578679482,"user_tz":-540,"elapsed":18,"user":{"displayName":"Jangmin O","userId":"17786016660281478273"}}},"outputs":[],"source":["def chars_token_ratio(dataset, tokenizer, prepare_sample_text, nb_examples=400):\n","    \"\"\"\n","    Estimate the average number of characters per token in the dataset.\n","    \"\"\"\n","    total_characters, total_tokens = 0, 0\n","    for _, example in tqdm(zip(range(nb_examples), iter(dataset)), total=nb_examples):\n","        text = prepare_sample_text(example)\n","        total_characters += len(text)\n","        if tokenizer.is_fast:\n","            total_tokens += len(tokenizer(text).tokens())\n","        else:\n","            total_tokens += len(tokenizer.tokenize(text))\n","\n","    return total_characters / total_tokens"]},{"cell_type":"code","execution_count":13,"id":"e83ee095-d8a8-4618-8d62-29ef7b38bc28","metadata":{"id":"e83ee095-d8a8-4618-8d62-29ef7b38bc28","executionInfo":{"status":"ok","timestamp":1720578679482,"user_tz":-540,"elapsed":18,"user":{"displayName":"Jangmin O","userId":"17786016660281478273"}}},"outputs":[],"source":["def function_prepare_sample_text(tokenizer, for_train=True):\n","    \"\"\"클로저\"\"\"\n","\n","    def _prepare_sample_text(example):\n","        \"\"\"Prepare the text from a sample of the dataset.\"\"\"\n","        user_prompt=\"너는 사용자가 입력한 주문 문장을 분석하는 에이전트이다. 주문으로부터 이를 구성하는 음식명, 옵션명, 수량을 차례대로 추출해야 한다.\\n### 주문 문장: \"\n","        messages = [\n","            # {\"role\": \"system\", \"content\": f\"{system_prompt}\"},\n","            {\"role\": \"user\", \"content\": f\"{user_prompt}{example['input']}\"},\n","        ]\n","        if for_train:\n","            messages.append({\"role\": \"assistant\", \"content\": f\"{example['output']}\"})\n","\n","        text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=False if for_train else True)\n","        return text\n","    return _prepare_sample_text"]},{"cell_type":"code","execution_count":14,"id":"dde80015-14c3-4c84-a529-cdb784c9792c","metadata":{"id":"dde80015-14c3-4c84-a529-cdb784c9792c","executionInfo":{"status":"ok","timestamp":1720578679482,"user_tz":-540,"elapsed":17,"user":{"displayName":"Jangmin O","userId":"17786016660281478273"}}},"outputs":[],"source":["def create_datasets(tokenizer, dataset, seq_length):\n","\n","    prepare_sample_text = function_prepare_sample_text(tokenizer)\n","\n","    chars_per_token = chars_token_ratio(dataset, tokenizer, prepare_sample_text)\n","    print(\n","        f\"The character to token ratio of the dataset is: {chars_per_token:.2f}\"\n","    )\n","\n","    cl_dataset = ConstantLengthDataset(\n","        tokenizer,\n","        dataset,\n","        formatting_func=prepare_sample_text,\n","        infinite=True,\n","        seq_length=seq_length,\n","        chars_per_token=chars_per_token,\n","    )\n","\n","    return cl_dataset"]},{"cell_type":"markdown","id":"5a15270e-9d1b-4f85-9b0f-dcbfe5d358b0","metadata":{"id":"5a15270e-9d1b-4f85-9b0f-dcbfe5d358b0"},"source":["# 데이터셋 생성"]},{"cell_type":"code","execution_count":15,"id":"476ca90e-a3eb-45d7-ae63-faec631e64a5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"476ca90e-a3eb-45d7-ae63-faec631e64a5","executionInfo":{"status":"ok","timestamp":1720578679962,"user_tz":-540,"elapsed":497,"user":{"displayName":"Jangmin O","userId":"17786016660281478273"}},"outputId":"4364b70a-e70d-4a8a-ee3e-c9633097b0d6"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 400/400 [00:00<00:00, 1098.87it/s]"]},{"output_type":"stream","name":"stdout","text":["The character to token ratio of the dataset is: 1.81\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["ds = create_datasets(tokenizer, full_dataset, seq_length)"]},{"cell_type":"code","execution_count":16,"id":"84d799e9-751d-4528-8baa-bed8ea6ea829","metadata":{"id":"84d799e9-751d-4528-8baa-bed8ea6ea829","executionInfo":{"status":"ok","timestamp":1720578679962,"user_tz":-540,"elapsed":1,"user":{"displayName":"Jangmin O","userId":"17786016660281478273"}}},"outputs":[],"source":["it = iter(ds)"]},{"cell_type":"code","execution_count":17,"id":"88bc95f8-4405-43b6-ba71-e4fe51eaa661","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":246},"id":"88bc95f8-4405-43b6-ba71-e4fe51eaa661","executionInfo":{"status":"ok","timestamp":1720578681330,"user_tz":-540,"elapsed":1369,"user":{"displayName":"Jangmin O","userId":"17786016660281478273"}},"outputId":"17c2e0a3-023a-4d9c-ca31-993f2d0dd53b"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/trl/trainer/utils.py:566: UserWarning: The dataset reached end and the iterator is reset to the start.\n","  warnings.warn(\"The dataset reached end and the iterator is reset to the start.\")\n"]},{"output_type":"execute_result","data":{"text/plain":["'문 문장을 분석하는 에이전트이다. 주문으로부터 이를 구성하는 음식명, 옵션명, 수량을 차례대로 추출해야 한다.\\n### 주문 문장: 바삭한 치킨이 먹고싶어요, 믿고 먹는 치하오닭다리 한판 처리해주세요.<end_of_turn>\\n<start_of_turn>model\\n- 분석 결과 0: 음식명:치하오닭다리, 수량:한판<end_of_turn>\\n<eos><bos><bos><start_of_turn>user\\n너는 사용자가 입력한 주문 문장을 분석하는 에이전트이다. 주문으로부터 이를 구성하는 음식명, 옵션명, 수량을 차례대로 추출해야 한다.\\n### 주문 문장: 갈릭브래드 있는 피자 1판 아주루이하게 주세요.<end_of_turn>\\n<start_of_turn>model\\n- 분석 결과 0: 음식명:갈릭브래드 있느 피자, 수량:1판<end_of_turn>\\n<eos><bos><bos><start_of_turn>user\\n너는 사용자가 입력한 주문 문장을 분석하는 에이전트이다. 주문으로부터 이를 구성하는 음식명, 옵션명, 수량을 차례대로 추출해야 한다.\\n### 주문 문장: 저는 땅콩을 좋아해서, 땅콩버터오징어 한 판에, 또 땅콩을 넣은 요거트스노우 한 캔 주세요.<end_of_turn>\\n<start_of_turn>model\\n- 분석 결과 0: 음식명:땅콩버터오징어, 수량:한판\\n- 분석 결과 1: 음식명:요거트스노우, 수량:한캔<end_of_turn>\\n<eos><bos><bos><start_of_turn>user\\n너는 사용자가 입력한 주문 문장을 분석하는 에이전트이다. 주문으로부터 이를 구성하는 음식명, 옵션명, 수량을 차례대로 추출해야 한다.\\n### 주문 문장: 보양닭곰탕 하나랑 순살치킨국떡 한 판 주세요. 또, 메밀막국수도 먹을게요.<end_of_turn>\\n<start_of_turn>model\\n- 분석 결과 0: 음식명:보양닭곰탕,수량:하나\\n- 분석 결과 1: 음식명:순살치킨국떡,수량:한 판\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":17}],"source":["tokenizer.decode(next(it)['input_ids'])"]},{"cell_type":"markdown","id":"4dab0c34-a994-4482-a539-d98ccfc74857","metadata":{"id":"4dab0c34-a994-4482-a539-d98ccfc74857"},"source":["# 훈련"]},{"cell_type":"markdown","source":["\n","훈련 시간 (에포크 1번)\n","- T4: 1시간 20분\n","- RTX4090: 10분\n","\n","로스\n","- 500  스텝: 0.552\n","- 1500 스텝: 0.432"],"metadata":{"id":"-hoC9TW6iEkg"},"id":"-hoC9TW6iEkg"},{"cell_type":"code","source":["from google.colab import userdata\n","import wandb\n","\n","wandb_api_key = userdata.get('WANDB_API_KEY')\n","if wandb_api_key:\n","    wandb.login(key=wandb_api_key)\n","    print(\"Successfully logged in to Weights & Biases\")\n","else:\n","    print(\"WANDB_API_KEY not found in Colab secrets\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EEqW7GcMeC54","executionInfo":{"status":"ok","timestamp":1720578692055,"user_tz":-540,"elapsed":4410,"user":{"displayName":"Jangmin O","userId":"17786016660281478273"}},"outputId":"09b7c5ae-722a-4dfb-9eaf-a14382ad3bc1"},"id":"EEqW7GcMeC54","execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"stream","name":"stdout","text":["Successfully logged in to Weights & Biases\n"]}]},{"cell_type":"code","execution_count":19,"id":"171a1cdf-2931-4cbe-bc68-20252e680fc3","metadata":{"id":"171a1cdf-2931-4cbe-bc68-20252e680fc3","executionInfo":{"status":"ok","timestamp":1720578697028,"user_tz":-540,"elapsed":373,"user":{"displayName":"Jangmin O","userId":"17786016660281478273"}}},"outputs":[],"source":["sft_config = SFTConfig(\n","    output_dir=output_dir,\n","    per_device_train_batch_size=2,\n","    gradient_accumulation_steps=1,\n","    gradient_checkpointing=False,\n","    learning_rate=1e-4,\n","    warmup_ratio=0.1,\n","    max_grad_norm=0.3,\n","    weight_decay=0.05,\n","    num_train_epochs=1,\n","    logging_steps=20,\n","    eval_strategy=\"no\",\n","    save_strategy=\"steps\",\n","    save_steps=50,\n","    save_total_limit=2,\n","    max_seq_length=seq_length,\n","    report_to=\"wandb\",\n","    run_name=\"gemma-2b-fine-tuning\"\n",")"]},{"cell_type":"code","execution_count":20,"id":"129069b9-d1f6-4a75-a304-b92484a1c751","metadata":{"id":"129069b9-d1f6-4a75-a304-b92484a1c751","executionInfo":{"status":"ok","timestamp":1720578702123,"user_tz":-540,"elapsed":781,"user":{"displayName":"Jangmin O","userId":"17786016660281478273"}}},"outputs":[],"source":["trainer = SFTTrainer(\n","    model=base_model,\n","    train_dataset=ds,\n","    eval_dataset=None,\n","    peft_config=peft_config,\n","    tokenizer=tokenizer,\n","    args=sft_config\n",")"]},{"cell_type":"code","execution_count":null,"id":"1e25629b-a831-4266-bf4a-8ea7d94a2403","metadata":{"id":"1e25629b-a831-4266-bf4a-8ea7d94a2403"},"outputs":[],"source":["trainer.train()"]},{"cell_type":"markdown","id":"005fb2f7-ac7b-43d5-b5dc-2299847479a8","metadata":{"id":"005fb2f7-ac7b-43d5-b5dc-2299847479a8"},"source":["# 검증"]},{"cell_type":"markdown","id":"4aacc509-e38f-4094-aa63-1499844a9b46","metadata":{"id":"4aacc509-e38f-4094-aa63-1499844a9b46"},"source":["## 검증 유틸리티"]},{"cell_type":"code","execution_count":22,"id":"94f94ccf-5e9a-4dc8-87fb-383f138789a8","metadata":{"id":"94f94ccf-5e9a-4dc8-87fb-383f138789a8","executionInfo":{"status":"ok","timestamp":1720580059054,"user_tz":-540,"elapsed":319,"user":{"displayName":"Jangmin O","userId":"17786016660281478273"}}},"outputs":[],"source":["def wrapper_generate(tokenizer, model, input_prompt, do_stream=False):\n","    def get_text_after_prompt(text):\n","        pattern = r'<start_of_turn>model\\n(.*?)<end_of_turn>'\n","        match = re.search(pattern, text, re.DOTALL)\n","\n","        if match:\n","            extracted_text = match.group(1).strip()\n","            return extracted_text\n","        else:\n","            return \"매칭되는 텍스트가 없습니다.\"\n","\n","    data = tokenizer(input_prompt, return_tensors=\"pt\")\n","    streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n","    input_ids = data.input_ids[..., :-1]\n","    with torch.no_grad():\n","        pred = model.generate(\n","            input_ids=input_ids.cuda(),\n","            streamer=streamer if do_stream else None,\n","            use_cache=True,\n","            max_new_tokens=float(\"inf\"),\n","            do_sample=False,\n","            pad_token_id=tokenizer.pad_token_id,\n","            eos_token_id=tokenizer.eos_token_id,\n","        )\n","    decoded_text = tokenizer.batch_decode(pred, skip_special_tokens=False)\n","\n","    # gemma 결과에 대해 특별 처리\n","    return get_text_after_prompt(decoded_text[0])"]},{"cell_type":"markdown","id":"12481e6d-5883-43c8-b352-b82d8b1b31dc","metadata":{"id":"12481e6d-5883-43c8-b352-b82d8b1b31dc"},"source":["## 훈련된 모델 로딩"]},{"cell_type":"code","execution_count":null,"id":"dfe160f6-d1b6-4247-a45f-377fc1024d32","metadata":{"colab":{"referenced_widgets":["dca598c9f2034791a0d9b1e8464d345b"]},"id":"dfe160f6-d1b6-4247-a45f-377fc1024d32","outputId":"61a4c629-bce0-40c4-a008-f4bd045480d4"},"outputs":[{"name":"stderr","output_type":"stream","text":["`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n","Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n","`config.hidden_activation` if you want to override this behaviour.\n","See https://github.com/huggingface/transformers/pull/29402 for more details.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dca598c9f2034791a0d9b1e8464d345b","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["trained_model = (\n","    AutoPeftModelForCausalLM.from_pretrained(\n","        f\"{output_dir}/checkpoint-1500\",\n","        quantization_config=bnb_config,\n","        device_map=\"auto\",  # {\"\": Accelerator().local_process_index},\n","        trust_remote_code=True,\n","    )\n",")"]},{"cell_type":"markdown","id":"3ec991b9-b69c-4680-a80f-e42865ec0dd5","metadata":{"id":"3ec991b9-b69c-4680-a80f-e42865ec0dd5"},"source":["## 테스트"]},{"cell_type":"code","execution_count":23,"id":"d64be61b-bdc8-4bc7-9af2-68bfd47284cb","metadata":{"id":"d64be61b-bdc8-4bc7-9af2-68bfd47284cb","executionInfo":{"status":"ok","timestamp":1720580074968,"user_tz":-540,"elapsed":407,"user":{"displayName":"Jangmin O","userId":"17786016660281478273"}}},"outputs":[],"source":["preprocessor = function_prepare_sample_text(tokenizer, for_train=False)"]},{"cell_type":"code","execution_count":24,"id":"b5e8b12f-cbd1-469f-96ee-7bbe2cdb788e","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"b5e8b12f-cbd1-469f-96ee-7bbe2cdb788e","executionInfo":{"status":"ok","timestamp":1720580075434,"user_tz":-540,"elapsed":4,"user":{"displayName":"Jangmin O","userId":"17786016660281478273"}},"outputId":"d2f34468-c0b9-42a0-80f1-702794c9649e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'<bos><start_of_turn>user\\n너는 사용자가 입력한 주문 문장을 분석하는 에이전트이다. 주문으로부터 이를 구성하는 음식명, 옵션명, 수량을 차례대로 추출해야 한다.\\n### 주문 문장: 아이스아메리카노 그랑데 한잔 주세요<end_of_turn>\\n<start_of_turn>model\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":24}],"source":["preprocessor({'input':'아이스아메리카노 그랑데 한잔 주세요'})"]},{"cell_type":"code","execution_count":25,"id":"bb164b1a-84eb-4a9b-8ab3-e19d91553d78","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"bb164b1a-84eb-4a9b-8ab3-e19d91553d78","executionInfo":{"status":"ok","timestamp":1720580100497,"user_tz":-540,"elapsed":11713,"user":{"displayName":"Jangmin O","userId":"17786016660281478273"}},"outputId":"a3f217b0-05d3-4910-b9d1-188aa982d97e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'- 분석 결과 0: 음식명:아이스아메리카노,옵션:그랑데,수량:한잔\\n- 분석 결과 1: 음식명:베이글,수량:두개'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":25}],"source":["wrapper_generate(tokenizer=tokenizer, model=trained_model, input_prompt=preprocessor({'input':'아이스아메리카노 그랑데 한잔 주세요. 그리고 베이글 두개요.'}))"]},{"cell_type":"code","execution_count":null,"id":"abb636ba-4133-48de-89a0-f26609e9b710","metadata":{"id":"abb636ba-4133-48de-89a0-f26609e9b710"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"f5bcd287d4fe401c9bec81288dc83cfd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_aeb93fee4c8c400a9883ffc945c76838","IPY_MODEL_669c3f8f432d4435a28136539f8c8328","IPY_MODEL_b05ece34370f418886cbcf8af5cd6adc"],"layout":"IPY_MODEL_1d871e675b8741f0b48f23300c9fc0ee"}},"aeb93fee4c8c400a9883ffc945c76838":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8f2a9534254341f9881df6e431f35e34","placeholder":"​","style":"IPY_MODEL_97ff3bb8e7a8499eb34b47104b9f8a17","value":"Loading checkpoint shards: 100%"}},"669c3f8f432d4435a28136539f8c8328":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f662959cb24145f7a33e82e92eab2025","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_84b08b2feef94d3eaa65dbdfb0f0e8b3","value":2}},"b05ece34370f418886cbcf8af5cd6adc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be76b22994dc48238836d805c9239642","placeholder":"​","style":"IPY_MODEL_c8887b8b829c475682ad5b21ebf7eb10","value":" 2/2 [00:20&lt;00:00,  8.34s/it]"}},"1d871e675b8741f0b48f23300c9fc0ee":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f2a9534254341f9881df6e431f35e34":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97ff3bb8e7a8499eb34b47104b9f8a17":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f662959cb24145f7a33e82e92eab2025":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"84b08b2feef94d3eaa65dbdfb0f0e8b3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be76b22994dc48238836d805c9239642":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8887b8b829c475682ad5b21ebf7eb10":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":5}